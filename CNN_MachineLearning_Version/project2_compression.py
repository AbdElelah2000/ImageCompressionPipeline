# -*- coding: utf-8 -*-
"""project2_compression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Px7SgN_XRXrSa2fx6zisGtXByHu7t_Fr
"""

#!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip
#!unzip /content/drive/MyDrive/training/DIV2K_valid_HR.zip

import tensorflow as tf
import cv2
import numpy as np
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from glob import glob
from tqdm import tqdm

# Defining all necessary functions first:-
def CNN_downsampling(image):
    # Load pre-trained models for 2x and 4x downsampling
    downsample_2x_model = load_model('/content/drive/MyDrive/training/model/2x_downsample_model.h5')
    downsample_4x_model = load_model('/content/drive/MyDrive/training/model/4x_downsample_model.h5')

    # Add a new axis to each input channel for compatibility with the model input
    input_y = np.expand_dims(image[:,:,0], axis=0)
    input_u = np.expand_dims(image[:,:,1], axis=0)
    input_v = np.expand_dims(image[:,:,2], axis=0)

    # Perform 2x upsampling for the Y channel using the 2x downsampling model
    y_downsampled = np.array(downsample_2x_model.predict(input_y))
    # Perform 4x upsampling for the U and V channels using the 4x downsampling model
    u_downsampled = np.array(downsample_4x_model.predict(input_u))
    v_downsampled = np.array(downsample_4x_model.predict(input_v))

    # Remove the added axis from the downsampled channels
    y_downsampled = np.squeeze(y_downsampled, axis=0)
    u_downsampled = np.squeeze(u_downsampled, axis=0)
    v_downsampled = np.squeeze(v_downsampled, axis=0)

    return y_downsampled, u_downsampled, v_downsampled

def CNN_upsample_image(input_y, input_u, input_v):
    # Load pre-trained models for 2x and 4x upsampling
    upsample_2x_model = load_model('/content/drive/MyDrive/training/model/2x_upsample_model.h5')
    upsample_4x_model = load_model('/content/drive/MyDrive/training/model/4x_upsample_model.h5')

    # Add a new axis to each input channel for compatibility with the model input
    input_y = np.expand_dims(input_y, axis=0)
    input_u = np.expand_dims(input_u, axis=0)
    input_v = np.expand_dims(input_v, axis=0)

    # Perform 2x upsampling for the Y channel using the 2x upsampling model
    y_upsampled = np.array(upsample_2x_model.predict(input_y))
    # Perform 4x upsampling for the U and V channels using the 4x upsampling model
    u_upsampled = np.array(upsample_4x_model.predict(input_u))
    v_upsampled = np.array(upsample_4x_model.predict(input_v))

    # Remove the added axis from the upsampled channels
    y_upsampled = np.squeeze(y_upsampled, axis=0)
    u_upsampled = np.squeeze(u_upsampled, axis=0)
    v_upsampled = np.squeeze(v_upsampled, axis=0)

    # Stack the upsampled Y, U, and V channels along the depth (third) axis
    yuv_image = np.dstack((y_upsampled, u_upsampled, v_upsampled))

    # Convert the upsampled YUV image to RGB format using the convert_YUV2RGB function
    rgb_image = convert_YUV2RGB(yuv_image)
    return rgb_image

# Define the conversion matrices
Conversion_mat_RGB2YUV = np.array([[0.299, 0.587, 0.114], [0.5, -0.41869, -0.08131], [-0.16874, -0.33126, 0.5]])
Conversion_mat_YUV2RGB = np.array([[1.000, 0.000, 1.13983], [1.000, -0.39465, -0.58060], [1.000, 2.03211, 0.000]])

# A Function that converts rgb image to yuv image
def convert_RGB2YUV(rgb_image):
    yuv_image = np.zeros_like(rgb_image)
    yuv_image[:,:,0] = np.dot(rgb_image, Conversion_mat_RGB2YUV[0])
    yuv_image[:,:,1] = np.dot(rgb_image, Conversion_mat_RGB2YUV[1])
    yuv_image[:,:,2] = np.dot(rgb_image, Conversion_mat_RGB2YUV[2])
    image_rep = yuv_image[:,:,1:] + 128.0
    # 8-bit representation of the image
    yuv_image[:,:,1:] = image_rep.astype(np.uint8)

    return yuv_image


# Define the conversion matrices
Conversion_mat_YUV2BGR = np.array([[1.000, 0.000, 1.403], [1.000, -0.34413, -0.71414], [1.000, 1.773, 0.000]])
Conversion_mat_RGB2BGR = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])

# A Function that converts yuv image to bgr image
def convert_YUV2RGB(yuv_image):
    yuv_image = yuv_image.astype(np.float32)
    yuv_image[:,:,1:] = yuv_image[:,:,1:] - 128.0
    rgb_image = np.dot(yuv_image, Conversion_mat_YUV2RGB.T)
    # Convert from RGB to BGR color space This is because we need it in the BGR order to show the image correctly with openCV
    bgr_image = np.dot(rgb_image, Conversion_mat_RGB2BGR.T)
    # 8-bit representation of the image
    bgr_image = clip_values(bgr_image, 0, 255).astype(np.uint8)
    return bgr_image

# implementation of split
def split_image_channels(image):
    b_ch = image[:,:,0]
    g_ch = image[:,:,1]
    r_ch = image[:,:,2]
    return b_ch, g_ch, r_ch

# implementation of clip
def clip_values(array, min, max):
    clip = np.copy(array)
    # clip values
    clip[clip < min] = min
    clip[clip > max] = max
    return clip

# implementation of sum
def sum_array(array):
    sum = 0
    for i in range(array.shape[0]):
        for j in range(array.shape[1]):
            sum += array[i, j]
    return sum

def create_gaussian_kernel(kernel_size, sigma_value=1.5):
    # Generate Gaussian kernel for the given kernel size and sigma value
    kx = cv2.getGaussianKernel(kernel_size, sigma_value)
    ky = cv2.getGaussianKernel(kernel_size, sigma_value)
    
    # Create a 2D Gaussian kernel using the outer product of the 1D Gaussian kernels
    two_d_kernel = np.outer(kx, ky)
    
    return two_d_kernel

def compute_ssim_metric(img_a, img_b, window_size=11, const_1=0.01, const_2=0.03, sigma=1.5, dynamic_range=1):
    if img_a.shape != img_b.shape:
        raise ValueError("Input images must have the same dimensions.")

    # Constants for SSIM calculation
    Constant_1 = (const_1 * dynamic_range) ** 2
    Constant_2 = (const_2 * dynamic_range) ** 2
    gaussian_kernel = create_gaussian_kernel(window_size, sigma)

    # Compute the mean of each image using the Gaussian kernel
    mean_a = cv2.filter2D(img_a, -1, gaussian_kernel)
    mean_b = cv2.filter2D(img_b, -1, gaussian_kernel)

    mean_a_sq = mean_a ** 2
    mean_b_sq = mean_b ** 2
    mean_a_mean_b = mean_a * mean_b

    # Compute the variance of each image and the covariance between them
    var_a = cv2.filter2D(img_a * img_a, -1, gaussian_kernel) - mean_a_sq
    var_b = cv2.filter2D(img_b * img_b, -1, gaussian_kernel) - mean_b_sq
    cov_ab = cv2.filter2D(img_a * img_b, -1, gaussian_kernel) - mean_a_mean_b

    # Compute the SSIM map and the mean SSIM value
    ssim_map = ((2 * mean_a_mean_b + Constant_1) * (2 * cov_ab + Constant_2)) / ((mean_a_sq + mean_b_sq + Constant_1) * (var_a + var_b + Constant_2))
    ssim_mean = np.mean(ssim_map)

    return ssim_mean

def calc_psnr_value(img_a, img_b):
    # Check if both images have the same dimensions
    if img_a.shape != img_b.shape:
        raise ValueError("Error: Images have different dimensions")

    # Calculate mean squared error
    mean_sq_error = np.mean((img_a - img_b) ** 2)

    # Calculate PSNR (Peak Signal-to-Noise Ratio)
    if mean_sq_error == 0:
        return float('inf')
    else:
        psnr_value = 20 * np.log10(255 / np.sqrt(mean_sq_error))
        return psnr_value


def calc_mse_value(img_a, img_b):
    # Verify if the dimensions of both images are the same
    assert img_a.shape == img_b.shape
    # Compute the mean of the squared differences
    return np.mean((img_a - img_b) ** 2)


# Array to hold all SSIM and PSNR values
ssim_values = np.array([])
psnr_values = np.array([])
index = 1

# Iterate through the specified image files
for img_path in tqdm(glob('/content/DIV2K_valid_HR/083[1-7].png')):
    # Read the image and convert it to YUV color space
    img = cv2.imread(img_path)
    yuv_image = convert_RGB2YUV(img)

    # Downsample the YUV image
    y_downsampled, u_downsampled, v_downsampled = CNN_downsampling(yuv_image)
    cv2.imwrite(f'/content/drive/MyDrive/training/output_images/upsample/out/downsample/Y_downsample0{index}.jpg', y_downsampled)
    cv2.imwrite(f'/content/drive/MyDrive/training/output_images/upsample/out/downsample/U_downsample0{index}.jpg', u_downsampled)
    cv2.imwrite(f'/content/drive/MyDrive/training/output_images/upsample/out/downsample/V_downsample0{index}.jpg', v_downsampled)

    # Upsample the YUV image using the CNN model
    rgb_result = CNN_upsample_image(y_downsampled, u_downsampled, v_downsampled)

    # Calculate the PSNR value between the original and upsampled images
    psnr_value = calc_psnr_value(img, rgb_result)
    

    # Save the upsampled and original images
    cv2.imwrite(f'/content/drive/MyDrive/training/output_images/upsample/out/CNN_upsample0{index}.jpg', rgb_result)
    cv2.imwrite(f"/content/drive/MyDrive/training/output_images/upsample/in/input0{index}.jpg", img)

    # Read the original and upsampled images as grayscale for SSIM calculation
    img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255
    rgb_gray = cv2.imread(f'/content/drive/MyDrive/training/output_images/upsample/out/CNN_upsample0{index}.jpg', cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255

    # Calculate SSIM between the original and upsampled grayscale images
    ssim_value = compute_ssim_metric(img_gray, rgb_gray)

    print(f"\nMetrics for image {index}:-")
    print("\nPSNR:- ", psnr_value)
    print("SSIM:- ", ssim_value)

    # Append SSIM and PSNR values to the respective arrays
    ssim_values = np.append(ssim_values, ssim_value)
    psnr_values = np.append(psnr_values, psnr_value)

    # Increment the image index
    index += 1

Avg_ssim = np.sum(ssim_values)/len(ssim_values)
Avg_psnr = np.sum(psnr_values)/len(psnr_values)

print(f"\nAveraging SSIM value: {Avg_ssim}")
print(f"Averaging PSNR value: {Avg_psnr}")